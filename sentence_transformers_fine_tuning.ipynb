{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is (are) A guide to clinical trials for c...</td>\n",
       "      <td>0000001-1</td>\n",
       "      <td>information</td>\n",
       "      <td>If you have cancer, a clinical trial may be an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do you have information about A guide to herba...</td>\n",
       "      <td>0000002-1</td>\n",
       "      <td>information</td>\n",
       "      <td>Herbal remedies are plants used like a medicin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is (are) A1C test ?</td>\n",
       "      <td>0000003-1</td>\n",
       "      <td>information</td>\n",
       "      <td>A1C is a lab test that shows the average level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is (are) Aarskog syndrome ?</td>\n",
       "      <td>0000004-1</td>\n",
       "      <td>information</td>\n",
       "      <td>Aarskog syndrome is a very rare disease that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What causes Aarskog syndrome ?</td>\n",
       "      <td>0000004-2</td>\n",
       "      <td>causes</td>\n",
       "      <td>Aarskog syndrome is a genetic disorder that is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47242</th>\n",
       "      <td>What is (are) Parasites - Zoonotic Hookworm ?</td>\n",
       "      <td>0000440-1</td>\n",
       "      <td>information</td>\n",
       "      <td>There are many different species of hookworms,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47243</th>\n",
       "      <td>Who is at risk for Parasites - Zoonotic Hookwo...</td>\n",
       "      <td>0000440-2</td>\n",
       "      <td>susceptibility</td>\n",
       "      <td>Dog and cat hookworms are found throughout the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47244</th>\n",
       "      <td>How to diagnose Parasites - Zoonotic Hookworm ?</td>\n",
       "      <td>0000440-5</td>\n",
       "      <td>exams and tests</td>\n",
       "      <td>Cutaneous larva migrans (CLM) is a clinical di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47245</th>\n",
       "      <td>What are the treatments for Parasites - Zoonot...</td>\n",
       "      <td>0000440-6</td>\n",
       "      <td>treatment</td>\n",
       "      <td>The zoonotic hookworm larvae that cause cutane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47246</th>\n",
       "      <td>How to prevent Parasites - Zoonotic Hookworm ?</td>\n",
       "      <td>0000440-7</td>\n",
       "      <td>prevention</td>\n",
       "      <td>Wearing shoes and taking other protective meas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45877 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question question_id  \\\n",
       "0      What is (are) A guide to clinical trials for c...   0000001-1   \n",
       "5      Do you have information about A guide to herba...   0000002-1   \n",
       "6                               What is (are) A1C test ?   0000003-1   \n",
       "8                       What is (are) Aarskog syndrome ?   0000004-1   \n",
       "9                         What causes Aarskog syndrome ?   0000004-2   \n",
       "...                                                  ...         ...   \n",
       "47242      What is (are) Parasites - Zoonotic Hookworm ?   0000440-1   \n",
       "47243  Who is at risk for Parasites - Zoonotic Hookwo...   0000440-2   \n",
       "47244    How to diagnose Parasites - Zoonotic Hookworm ?   0000440-5   \n",
       "47245  What are the treatments for Parasites - Zoonot...   0000440-6   \n",
       "47246     How to prevent Parasites - Zoonotic Hookworm ?   0000440-7   \n",
       "\n",
       "         question_type                                             answer  \n",
       "0          information  If you have cancer, a clinical trial may be an...  \n",
       "5          information  Herbal remedies are plants used like a medicin...  \n",
       "6          information  A1C is a lab test that shows the average level...  \n",
       "8          information  Aarskog syndrome is a very rare disease that a...  \n",
       "9               causes  Aarskog syndrome is a genetic disorder that is...  \n",
       "...                ...                                                ...  \n",
       "47242      information  There are many different species of hookworms,...  \n",
       "47243   susceptibility  Dog and cat hookworms are found throughout the...  \n",
       "47244  exams and tests  Cutaneous larva migrans (CLM) is a clinical di...  \n",
       "47245        treatment  The zoonotic hookworm larvae that cause cutane...  \n",
       "47246       prevention  Wearing shoes and taking other protective meas...  \n",
       "\n",
       "[45877 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_medical_qa_dataset(n_samples=None):\n",
    "    \n",
    "    files = os.listdir('dataset/processed_data')\n",
    "\n",
    "    # Read the files into a dataframe\n",
    "    for idx, file in enumerate(files):\n",
    "        if idx == 0:\n",
    "            df = pd.read_csv('dataset/processed_data/' + file, na_values=['', ' ', 'No information found.'])\n",
    "        else:\n",
    "            df = pd.concat([df, pd.read_csv('dataset/processed_data/' + file, na_values=['', ' ', 'No information found.'])], ignore_index=True)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Select a subset of the data if n_samples is specified\n",
    "    if n_samples:\n",
    "        df = df.sample(n_samples)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_medical_qa_dataset(n_samples=None)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['susceptibility', 'treatment', 'symptoms', 'precautions',\n",
       "       'dietary', 'indication', 'prevention', 'side effects',\n",
       "       'genetic changes', 'information', 'causes', 'other information',\n",
       "       'storage and disposal', 'inheritance', 'outlook',\n",
       "       'exams and tests', 'usage', 'frequency', 'brand names',\n",
       "       'complications', 'when to contact a medical professional',\n",
       "       'considerations', 'forget a dose', 'research', 'important warning',\n",
       "       'support groups', 'emergency or overdose', 'how effective is it',\n",
       "       'brand names of combination products',\n",
       "       'interactions with medications',\n",
       "       'interactions with herbs and supplements', 'stages',\n",
       "       'how does it work'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.question_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InputExample> label: 5, texts: Who should get Rifabutin and why is it prescribed ?; Rifabutin helps to prevent or slow the spread of Mycobacterium avium complex disease (MAC; a bacterial infection that may cause serious symptoms) in patients with human immunodeficiency virus (HIV) infection. It is also used in combination with other medications to eliminate  H. pylori , a bacteria that causes ulcers. Rifabutin is in a class of medications called antimycobacterials. It works by killing the bacteria that cause infection. Antibiotics such as rifabutin will not work for colds, flu, or other viral infections. Using antibiotics when they are not needed increases your risk of getting an infection later that resists antibiotic treatment.\n"
     ]
    }
   ],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, questions, answers, question_type):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.question_type = question_type\n",
    "\n",
    "        self.label_idx = {'susceptibility': 0, \n",
    "                          'treatment': 1,\n",
    "                           'symptoms': 2, \n",
    "                           'precautions': 3,\n",
    "                           'dietary': 4,\n",
    "                            'indication': 5,\n",
    "                            'prevention': 6,\n",
    "                            'side effects': 7,\n",
    "                            'genetic changes': 8,\n",
    "                            'information': 9,\n",
    "                            'causes': 10,\n",
    "                            'other information': 11,\n",
    "                            'storage and disposal': 12,\n",
    "                            'inheritance': 13,\n",
    "                            'outlook': 14,\n",
    "                            'exams and tests': 15,\n",
    "                            'usage': 16,\n",
    "                            'frequency': 17,\n",
    "                            'brand names': 18,\n",
    "                            'complications': 19,\n",
    "                            'when to contact a medical professional': 20,\n",
    "                            'considerations': 21,\n",
    "                            'forget a dose': 22,\n",
    "                            'research': 23,\n",
    "                            'important warning': 24,\n",
    "                            'support groups': 25,\n",
    "                            'emergency or overdose': 26,\n",
    "                            'how effective is it': 27,\n",
    "                            'brand names of combination products': 28,\n",
    "                            'interactions with medications': 29,\n",
    "                            'interactions with herbs and supplements': 30,\n",
    "                            'stages': 31,\n",
    "                            'how does it work': 32}\n",
    "        \n",
    "     \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return InputExample(texts=[self.questions[idx], self.answers[idx]], label=self.label_idx[self.question_type[idx]])\n",
    "    \n",
    "\n",
    "# Create a dataset from the dataframe\n",
    "dataset = QADataset(df['question'].values, df['answer'].values, df['question_type'].values)\n",
    "\n",
    "# Ver ejemplo aleatorio\n",
    "n = random.randint(0, len(dataset))\n",
    "print(dataset[n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'input_ids': tensor([[  101,  2129,  2000,  4652, 17419,  2594, 27641,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2003,  1006,  2024,  1007,  5939,  7352,  3170, 10092,\n",
      "          2828,  1015,  1029,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2024,  1996,  8030,  1997, 11265,  8458, 29166, 12419,\n",
      "          2791, 24471,  3981,  2854, 12859,  3617, 15451, 14192,  3370,  1029,\n",
      "           102,     0,     0],\n",
      "        [  101,  2054,  2003,  1996,  2895,  1997, 19395, 11253, 14973,  2378,\n",
      "          1998,  2129,  2515,  2009,  2147,  1029,   102,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2024,  1996,  8030,  1997, 27281,  3536,  8715,  1029,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2003,  1006,  2024,  1007, 11190,  4181,  8715,  1029,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2024,  1996,  8030,  1997, 10047, 23041, 10244,  8873,\n",
      "         29125,  2007, 23760,  1045, 21693,  2828,  1016,  1029,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2003,  1006,  2024,  1007, 23760, 12399, 10092,  2005,\n",
      "         12318,  4456,  1029,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2003,  1006,  2024,  1007,  2695,  1011, 19686,  6911,\n",
      "          8761,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2040,  2003,  2012,  3891,  2005,  3609, 22471,  2389,  4456,\n",
      "          1029,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2129,  2000, 22939, 26745,  3366,  1043,  2135,  3597,  6914,\n",
      "          5527,  4295,  2828,  2410,  1029,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2024,  1996,  4435,  3415,  1997,  2022,  5332, 10258,\n",
      "         11636,  6305,  2378,  6728, 11039,  8865,  7712,  1029,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2024,  2045,  3808,  5936,  2030,  2569, 29361,  2055,  7279,\n",
      "         15464, 28173,  2638,  8700,  1999, 19531,  3508,  1029,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2024,  1996,  8030,  1997, 17710,  8609, 27381,  2863,\n",
      "          5340,  7361,  5802,  7559, 12403, 10074, 26287,  1029,   102,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2003,  1006,  2024,  1007,  5923,  7870,  1029,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2054,  2003,  1006,  2024,  1007,  2158,  4305,  8569,  4135,\n",
      "          7011, 13247,  1040,  7274, 14122, 12650,  2007, 12702,  3401, 21890,\n",
      "          2135,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[ 101, 4652, 3512,  ...,    0,    0,    0],\n",
      "        [ 101, 5939, 7352,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 2024,  ..., 4650, 1012,  102],\n",
      "        ...,\n",
      "        [ 101, 2054, 2024,  ..., 1037, 3696,  102],\n",
      "        [ 101, 2115, 5944,  ...,    0,    0,    0],\n",
      "        [ 101, 2158, 4305,  ..., 3098, 1999,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}], tensor([ 6,  9,  2, 32,  2,  9,  2,  9,  9,  0, 15, 18,  3,  2,  9,  9]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Sequential.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [features[\u001b[38;5;241m0\u001b[39m], features[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Obtiene las incrustaciones de las oraciones\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Calcula la pÃ©rdida\u001b[39;00m\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m train_loss(embeddings[\u001b[38;5;241m0\u001b[39m], embeddings[\u001b[38;5;241m1\u001b[39m], labels)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\APLN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\APLN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Sequential.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, models\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Carga el modelo\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Asume 'dataset' es una lista de InputExample\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=model.smart_batching_collate)\n",
    "\n",
    "# Define la funciÃ³n de pÃ©rdida\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# ConfiguraciÃ³n del optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "model.train()\n",
    "for epoch in range(1):  # Ajusta el nÃºmero de Ã©pocas segÃºn sea necesario\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(batch)\n",
    "        \n",
    "        \n",
    "        # Las entradas ya estÃ¡n en el formato correcto gracias a smart_batching_collate\n",
    "        features, labels = batch\n",
    "        # features contiene dos listas: una para cada texto en los InputExamples\n",
    "        sentences = [features[0], features[1]]\n",
    "\n",
    "        # Obtiene las incrustaciones de las oraciones\n",
    "        embeddings = model(sentences[0], sentences[1])\n",
    "\n",
    "        # Calcula la pÃ©rdida\n",
    "        loss = train_loss(embeddings[0], embeddings[1], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Para guardar el modelo, utiliza model.save()\n",
    "model.save(\"path_to_save_your_finetuned_model\")\n",
    "print(\"Modelo fine-tuneado guardado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m     texts \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtexts)))  \u001b[38;5;66;03m# Transpone la lista de textos\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(texts, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[25], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m     18\u001b[0m     texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtexts)))  \u001b[38;5;66;03m# Transpone la lista de textos\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(texts, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'texts'"
     ]
    }
   ],
   "source": [
    "# Carga el modelo\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=model.smart_batching_collate)\n",
    "\n",
    "# Define la loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# ConfiguraciÃ³n del optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "model.train()\n",
    "for epoch in range(1):  # Ajusta el nÃºmero de Ã©pocas segÃºn sea necesario\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        texts = [example.texts for example in batch]\n",
    "        texts = list(map(list, zip(*texts)))  # Transpone la lista de textos\n",
    "        encodings = model.encode(texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        loss = train_loss(encodings[0], encodings[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "# Guarda el modelo fine-tuneado\n",
    "# model.save(\"path_to_save_your_finetuned_model\")\n",
    "print(\"Modelo fine-tuneado guardado\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APLN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
